# This datafile documents all the possible optimizations that the optimizer can/should do.
# It is parsed by the parser described in fpoptimizer_grammar_gen.y, which
# is compiled into C++ code in fpoptimizer_grammar_gen.cc. The parser produces
# a C++ file, fpoptimizer_grammar.cc , which lists the grammar rules in tabular
# format. The grammar rules are utilized by fpoptimizer_optimize.cc , which
# matches the function trees into the rules and performing those replacements
# which can be performed.
#
# Copyright 2009 Joel Yliluoma, written specifically
#               for Warp's Function Parser (fparser).
#

# Substitution rule syntax:
#
# %token NUMERIC_CONSTANT     # literals such as 0, 1, 1.5 or CONSTANT_DR, CONSTANT_L10I
# %token PARAMETER_TOKEN      # placeholders such as x, y, a, b
# %token POSITIVE_PARAM_TOKEN # placeholders p and q, which match POSITIVE params only
# %token NEGATIVE_PARAM_TOKEN # placeholders m and n, which match NEGATIVE params only
# %token EVEN_PARAM_TOKEN     # placeholders e and f, which match EVEN params only
# %token NONEVEN_PARAM_TOKEN  # placeholders g and h, which match anything but EVEN params
# %token ODD_PARAM_TOKEN      # placeholders o and r, which match ODD params only
# %token PLACEHOLDER_TOKEN    # placeholders such as <1>, <2>, <7>
# %token IMMED_TOKEN          # placeholders % and &
# %token BUILTIN_FUNC_NAME    # such as COS, CEIL, POW, +, *, MIN, MAX
# %token OPCODE               # opcodes
# %token UNARY_TRANSFORMATION  # /, -, !  # inverts/negates/inverts the param
# %token NEWLINE              # newline
#
# %token SUBST_OP_COLON       # :
# %token SUBST_OP_ARROW       # ->
#
# %%
#     grammar:
#       grammar substitution
#     | grammar NEWLINE
#     | /* empty */
#     ;
#
#     substitution:
#       function SUBST_OP_ARROW param NEWLINE
#       /* Entire function is changed into the particular param */
#
#     | function SUBST_OP_ARROW function NEWLINE
#       /* Entire function changes, the param_notinv_list is rewritten */
#       /* NOTE: "p x -> o y"  is a shortcut for "p x -> (o y)"  */
#
#     | function SUBST_OP_COLON  paramlist NEWLINE
#       /* The params provided are replaced with the new param_maybeinv_list */
#     ;
#
#     function:
#        OPCODE '[' paramlist sign_spec ']'
#        /* Match a function with opcode=opcode,
#         * and the exact parameter list as specified
#         */
#        OPCODE '{' paramlist sign_spec '}'
#        /* Match a function with opcode=opcode,
#         * and the exact parameter list in any order
#         */
#     |  OPCODE paramlist sign_spec
#        /* Match a function with opcode=opcode and the given way of matching params */
#        /* There may be more parameters, don't care about them */
#     ;
#
#     paramlist: /* left-recursive list of 0-n params with no delimiter */
#         paramlist '~' param /* negated/inverted param */
#       | paramlist param
#       | /* empty */
#     ;
#
#     sign_spec: /* Can be used to specify a proportion of negativeness to positiveness */
#         '=-' /* ~<number> matched more elements than <number> did */
#       | '=+' /* ~<number> matched fewer elements than <number> did */
#       | '==' /* ~<number> matched as many elements than <number> did */
#       | /* empty */
#     ;
#
#     param:
#        NUMERIC_CONSTANT         /* particular immed */
#     |  IMMED_TOKEN              /* a placeholder for some immed */
#     |  BUILTIN_FUNC_NAME '(' paramlist ')'  /* literal logarithm/sin/etc. of the provided immed-type params -- also sum/product/minimum/maximum */
#     |  UNARY_TRANSFORMATION param   /* the negated/inverted literal value of the param */
#     |  expression_param         /* expression param */
#     |  expression_param '+'      /* expression param, repeated 2..N times. */
#     |  expression_param '*'      /* expression param, repeated 1..N times. */
#     |  '(' function ')'         /* a subtree */
#     |  PLACEHOLDER_TOKEN        /* a placeholder for all params */
#     ;
#
#     expression_param:
#        PARAMETER_TOKEN          /* any expression, indicated by "x", "a" etc. */
#      | POSITIVE_PARAM_TOKEN
#      | NEGATIVE_PARAM_TOKEN
#      | EVEN_PARAM_TOKEN
#      | NONEVEN_PARAM_TOKEN
#      | ODD_PARAM_TOKEN
#     ;


[BASIC]

###### Note: Before adding new rules (especially those which handle constant values),
######       verify that it is not already done in ConstantFolding().

#### Remove redundant components:

# In a add-list, having x and -x gets both deleted
cAdd x ~x  :
# In a mul-list,  having x and 1/x gets both deleted
cMul x ~x  :
# In a min-list, two identical components are reduced into one
cMin x x    : x
# In a max-list, two identical components are reduced into one
cMax x x    : x

# If both branches of an If() are identical, the test becomes unnecessary
cIf [y x x] -> x
# If the If() condition begins with a not, remove the not and swap the branches
cIf [(cNot x) y z]    -> cIf [x z y]
# Notnots are unnecessary in an If()
cIf [(cNotNot x) y z] -> cIf [x y z]

# There are more optimizations that could be done with If(),
# but they are likely too specific.
# For example:
#  Move branch invariants. if(y, x+a, x+b) -> x+if(y, a, b)
#  TODO: Figure out why these rules never match.
cIf [y       x           (cAdd x <1> ~<2>)] -> cAdd[x (cIf [y 0               (cAdd <1> ~<2>)])]
cIf [y (cAdd x <1> ~<2>) (cAdd x <3> ~<4>)] -> cAdd[x (cIf [y (cAdd <1> ~<2>) (cAdd <3> ~<4>)])]
cIf [y       x           (cMul x <1> ~<2>)] -> cMul[x (cIf [y 1               (cMul <1> ~<2>)])]
cIf [y (cMul x <1> ~<2>) (cMul x <3> ~<4>)] -> cMul[x (cIf [y (cMul <1> ~<2>) (cMul <3> ~<4>)])]
cIf [y       x           (cAnd x <1> ~<2>)] -> cAnd[x (cIf [y 0               (cAnd <1> ~<2>)])]
cIf [y (cAnd x <1> ~<2>) (cAnd x <3> ~<4>)] -> cAnd[x (cIf [y (cAnd <1> ~<2>) (cAnd <3> ~<4>)])]
cIf [y       x           (cOr  x <1> ~<2>)] -> cOr [x (cIf [y 1               (cOr  <1> ~<2>)])]
cIf [y (cOr  x <1> ~<2>) (cOr  x <3> ~<4>)] -> cOr [x (cIf [y (cOr  <1> ~<2>) (cOr  <3> ~<4>)])]

#### Flattening the topology of add/mul/min/max/and/or groups:

# If a add-list contains another add-list, assimilate the child (but xor the signs)
cAdd  (cAdd <1> ~<2>)  :  <1> ~<2>
cAdd ~(cAdd <1> ~<2>)  : ~<1>  <2>

# If a mul-list contains another mul-list, assimilate the child (but xor the signs)
cMul  (cMul <1> ~<2>)  :  <1> ~<2>
cMul ~(cMul <1> ~<2>)  : ~<1>  <2>

# If an add-list contains a mul-list with a negated entry, assimilate the negation.
# I.e.  a + b + (c * (-d-e+f))  ->  a + b - (c * (+d+e-f))
# Or    a + b - (c * (-d-e+f))  ->  a + b + (c * (+d+e-f))
cAdd  (cMul (cAdd <3> ~<4> =-) <1> ~<2>) : ~(cMul (cAdd ~<3> <4>) <1> ~<2>)
cAdd ~(cMul (cAdd <3> ~<4> =-) <1> ~<2>) :  (cMul (cAdd ~<3> <4>) <1> ~<2>)

# If a min-list contains another min-list, assimilate the child
cMin (cMin <1>)   : <1>

# If a max-list contains another max-list, assimilate the child
cMax (cMax <1>)   : <1>

# If an and-list contains not-tokens, assimilate those not-tokens
cAnd  (cNot[x])   : ~x
cAnd ~(cNot[x])   : x

# A notnot in and-lists is redundant:
cAnd  (cNotNot[x]) :  x
cAnd ~(cNotNot[x]) : ~x

# If an or-list contains not-tokens, assimilate those not-tokens
cOr  (cNot[x])   : ~x
cOr ~(cNot[x])   : x

# A notnot in or-lists is redundant:
cOr   (cNotNot[x]) :  x
cOr  ~(cNotNot[x]) : ~x

# If an and-list contains another and-list, assimilate the child
cAnd  (cAnd <1> ~<2>)  : <1> ~<2>
cAnd ~(cAnd <1> ~<2>)  : ~<1> <2>

# If an or-list contains another or-list, assimilate the child
cOr  (cOr <1> ~<2>)  : <1> ~<2>
cOr ~(cOr <1> ~<2>)  : ~<1> <2>

# Two notnots make one
cNotNot [(cNotNot[x])] : x
# A notnot-not is better expressed as not-notnot
cNotNot [(cNot[x])] -> cNot [(cNotNot [x])]


#### Linear combining and polynomials

# If a mul-list contains the same element two or more times,
# replace the element with a pow with an integer exponent
# (note: inversions are treated as a negative exponent)
# e.g. ...*x*x*x*x = ...*x^4
cMul  x+                   : (cPow  x  x+)
cMul ~x+                   : (cPow [x -x+])
# x^3 * x = x^4
cMul  x*       (cPow[x y]) : (cPow [x (cAdd x* y)])
cMul  x*      ~(cPow[x y]) : (cPow [x (cAdd x* ~y)])
cMul ~x*       (cPow[x y]) : (cPow [x (cAdd -x* y)])
cMul ~x*      ~(cPow[x y]) : (cPow [x (cAdd -x* ~y)])
# x^y * x^z = x^(y+z)
cMul  (cPow[x y])  (cPow[x z]) : (cPow [x (cAdd [y z])])
# x^y / x^z = x^(y-z)
cMul  (cPow[x y]) ~(cPow[x z]) : (cPow [x (cAdd [y ~z])])
# 1 / x^y / x^z = x^(-y-z)
cMul ~(cPow[x y]) ~(cPow[x z]) : (cPow [x (cAdd [~y ~z])])
# x^3 +



# If an add-list contains the same element two or more times,
# replace the element with a mul with an integer factor
# (note: negations are treated as a negative factor)
# e.g. ...+x+x+x+x -> ...+x*4
cAdd  x+                           :  (cMul  x   x+)
cAdd ~x+                           : ~(cMul  x   x+)

# Note: existence of x+ ~x+ is already dealt with by "cAdd x ~x :".
# x*3 + x*z*y = x*(3+z*y)
cAdd  x*          (cMul x <1> ~<2>)    : (cMul [x   (cAdd   x*  (cMul <1> ~<2>) )])
cAdd  x*         ~(cMul x <1> ~<2>)    : (cMul [x   (cAdd   x* ~(cMul <1> ~<2>) )])
cAdd ~x*          (cMul x <1> ~<2>)    : (cMul [x   (cAdd  ~x*  (cMul <1> ~<2>) )])
cAdd ~x*         ~(cMul x <1> ~<2>)    : (cMul [x   (cAdd  ~x* ~(cMul <1> ~<2>) )])


#### Remote double negations/inversions

# If a pow has an exponent of 1, replace the pow with the base value
cPow [x 1]  -> x

# If a pow has an exponent of -1, replace the pow with the base value inverted
cPow [x -1] -> cMul [~x]

# If an addlist contains a negated mul and that mul-list contains a factor,
# un-negate the mul-list and negate the factor in the mul-list.
cAdd ~(cMul % <1> ~<2>)      : (cMul -% <1> ~<2>)

# If a mul-list contains the immed -1, remove
# the immed and wrap the rest in a negated cAdd.
# Note: This is not done to all negative immeds,
#       otherwise the rule above will revert it.
cMul -1 <1> ~<2>             -> cAdd ~(cMul <1> ~<2>)

# -x * -y -> -(x*y)
cMul (cAdd [~x]) (cAdd [~y]) : (cAdd ~(cMul [x y]))

# If an exponent is negated, negate it and wrap
# the rest in an inverted cMul.
cPow [ x (cAdd <1> ~<2> =-) ] -> cMul ~(cPow [x (cAdd ~<1> <2>)])
#cPow [ x n ]                  -> cMul ~(cPow [x (cAdd ~n)])
# ^ conflicts with cMul ~(cPow [x %])

# If a mul-list contains an inverted pow and the exponent is an immed,
# un-negate the pow and negate the immed.
cMul ~(cPow [x %])           : (cPow [x -%])

# (x^g)^z        -> x^(g*z)  (g is not an even integer)
# FIXME: Should this be only done for odd integers?
# Because "not even" _can_ be even, we just don't know for sure
cPow [ (cPow[x g]) z ]       : x (cMul [g z])
# (x^e)^z        -> abs(x)^(e*z)  (e is an even integer)
cPow [ (cPow[x e]) z ]       : (cAbs [x]) (cMul [e z])

cPow [(cPow [p y]) z]        : p (cMul [y z])

#### Logical optimizations

# Repetitions in and-lists don't help
cAnd  x x   : x
cAnd ~x ~x  : ~x
# Nor in or-lists
cOr   x  x  : x
cOr  ~x ~x  : ~x

# In an and-list, having x and !x invalides the whole list
cAnd x ~x   -> 0

# In an or-list, having x and !x validates the whole list
cOr x ~x    -> 1

#   x==x -- this statement is always true (note: might be not when we have NaN, but we don't care)
cEqual[x x]                     -> 1
cLessOrEq[x x]                  -> 1
cGreaterOrEq[x x]               -> 1

#   x!=x -- this statement is always false (note: we ignore NaN cases)
cNEqual[x x]                    -> 0
cLess[x x]                      -> 0
cGreater[x x]                   -> 0

# Eschew so many negations.
#   !a & !b = !(a | b)
cAnd <1> ~<2> =- : ~(cOr <2> ~<1>)
#   !a | !b = !(a & b)
cOr <1> ~<2> =- : ~(cAnd <2> ~<1>)

cAnd ~(cNEqual[a b])      : (cEqual[a b])
cAnd ~(cEqual[a b])       : (cNEqual[a b])
cAnd ~(cLess[a b])        : (cGreaterOrEq[a b])
cAnd ~(cGreater[a b])     : (cLessOrEq[a b])
cAnd ~(cLessOrEq[a b])    : (cGreater[a b])
cAnd ~(cGreaterOrEq[a b]) : (cLess[a b])
cOr ~(cNEqual[a b])       : (cEqual[a b])
cOr ~(cEqual[a b])        : (cNEqual[a b])
cOr ~(cLess[a b])         : (cGreaterOrEq[a b])
cOr ~(cGreater[a b])      : (cLessOrEq[a b])
cOr ~(cLessOrEq[a b])     : (cGreater[a b])
cOr ~(cGreaterOrEq[a b])  : (cLess[a b])
cNot [(cNEqual[a b])]      -> cEqual[a b]
cNot [(cEqual[a b])]       -> cNEqual[a b]
cNot [(cLess[a b])]        -> cGreaterOrEq[a b]
cNot [(cGreater[a b])]     -> cLessOrEq[a b]
cNot [(cLessOrEq[a b])]    -> cGreater[a b]
cNot [(cGreaterOrEq[a b])] -> cLess[a b]
cNot [(cAnd <1> ~<2>)]     -> cOr  ~<1> <2>
cNot [(cOr  <1> ~<2>)]     -> cAnd ~<1> <2>
cNotNot [(cNEqual[a b])]      -> cNEqual[a b]
cNotNot [(cEqual[a b])]       -> cEqual[a b]
cNotNot [(cLess[a b])]        -> cLess[a b]
cNotNot [(cGreater[a b])]     -> cGreater[a b]
cNotNot [(cLessOrEq[a b])]    -> cLessOrEq[a b]
cNotNot [(cGreaterOrEq[a b])] -> cGreaterOrEq[a b]
cNotNot [(cAnd <1> ~<2>)]     -> cAnd <1> ~<2>
cNotNot [(cOr  <1> ~<2>)]     -> cOr  <1> ~<2>

# From logic, follows that...
#   (a==b) & (b==c) & (a==c) -- one of these is redundant
cAnd (cEqual[a b]) (cEqual[b c]) (cEqual[a c])  : (cEqual[a b]) (cEqual[b c])
#   (a==b) & (a!=b)          -- this statement is always false
cAnd (cEqual[a b]) (cNEqual[a b]) -> 0
#   (a==b) | (a!=b)          -- this statement is always true
cOr  (cEqual[a b]) (cNEqual[a b]) -> 1

cAnd (cLess[a b]) (cGreater[a b]) -> 0
cAnd (cLessOrEq[a b]) (cGreater[a b]) -> 0
cAnd (cLess[a b]) (cGreaterOrEq[a b]) -> 0
cOr (cLess[a b]) (cGreater[a b]) -> 1
cOr (cLessOrEq[a b]) (cGreater[a b]) -> 1
cOr (cLess[a b]) (cGreaterOrEq[a b]) -> 1






[ENTRY]
# These optimizations are done only once, before the intermediate conversions.
# This process converts some optimized opcodes into primitives, so as to
# make the intermediate optimizations simpler to write. In the final stage,
# the optimized opcodes are reconstructed where available.

# not(not(x)) = notnot(x)
# Do this so that !!x won't get inadvertedly optimized into x
# However, optimizing !!!x into !x is allright, and we do quite
# many things relating to cNot, so cNotNot helps protecting the
# one special case without having to repeat protections everywhere.
cNot[(cNot [x])] -> cNotNot [x]

#        asinh: log(x + sqrt(x*x + 1))
cAsinh [x] -> cLog (cAdd x (cPow (cAdd (cPow x 2) 1) 0.5))

#        acosh: log(x + sqrt(x*x - 1))
cAcosh [x] -> cLog (cAdd x (cPow (cAdd (cPow x 2) -1) 0.5))

#        atanh: log( (1+x) / (1-x)) / 2
cAtanh [x] -> cMul (cLog (cMul (cAdd 1 x) ~(cAdd 1 ~x))) 0.5

#     The hyperbolic functions themselves are:
#        sinh: (exp(x)-exp(-x)) / 2
cSinh [x] -> cMul 0.5 (cAdd (cPow [CONSTANT_E x]) ~(cMul [~(cPow [CONSTANT_E x])]))

#        cosh: (exp(x)+exp(-x)) / 2
#        cosh(-x) = cosh(x)
cCosh [x] -> cMul 0.5 (cAdd (cPow [CONSTANT_E x])  (cMul [~(cPow [CONSTANT_E x])]))

#        tanh: sinh/cosh = (exp(2*x)-1) / (exp(2*x)+1)
cTanh [x] -> (cMul (cAdd {(cPow [CONSTANT_E (cMul {2 x})]) -1}) ~(cAdd {(cPow [CONSTANT_E (cMul {2 x})]) 1}))

#        tan: sin/cos
cTan [x] -> (cMul (cSin [x]) ~(cCos [x]))

# Should we change sin(x) into cos(pi/2-x)
#               or cos(x) into sin(pi/2-x)?
#                        note: cos(x-pi/2) = cos(pi/2-x) = sin(x)
#                        note: sin(x-pi/2) = -sin(pi/2-x) = -cos(x)


[INTERMEDIATE]

# Opcodes we will NOT find in the intermediate stage:
#  Done by bytecode parser:
#   Meta opcodes: cDup, cNop, cFetch, cPopNMov, cJump
#   Meta opcodes: cVar, cImmed
#   Implemented through cMul: cDiv, cRDiv, cInv, cSqr
#   Implemented through cAdd: cSub, cRSub, cNeg
#   Implemented through constant-multiplying: cDeg, cRad
#   Implemented through cSin, cCos: cCot, cCsc, cSec, cTan
#   Implemented through cPow: cSqrt, cExp
#   Implemented through cLog: cLog2, cLog10
#  Done by entry rules:
#   Extracted: cAsinh, cAcosh, cAtanh
#   Extracted: cSinh, cCosh, cTanh

#### CONTINUED: Flattening the topology of add/mul/min/max/and/or groups

#  +(x*A*B/C) +(x*D*E/F) = x*(+A*B/C +D*E/F)
#cAdd  (cMul  x <1> ~<3>)  (cMul  x <2> ~<4>)   : (cMul [ x (cAdd  (cMul <1> ~<3>)  (cMul <2> ~<4>))])
#cAdd  (cMul  x <1> ~<3>) ~(cMul  x <2> ~<4>)   : (cMul [ x (cAdd  (cMul <1> ~<3>) ~(cMul <2> ~<4>))])
#cAdd ~(cMul  x <1> ~<3>) ~(cMul  x <2> ~<4>)   : (cMul [ x (cAdd ~(cMul <1> ~<3>) ~(cMul <2> ~<4>))])
#cAdd  (cMul ~x <1> ~<3>)  (cMul ~x <2> ~<4>)   : (cMul [~x (cAdd  (cMul <1> ~<3>)  (cMul <2> ~<4>))])
#cAdd  (cMul ~x <1> ~<3>) ~(cMul ~x <2> ~<4>)   : (cMul [~x (cAdd  (cMul <1> ~<3>) ~(cMul <2> ~<4>))])
#cAdd ~(cMul ~x <1> ~<3>) ~(cMul ~x <2> ~<4>)   : (cMul [~x (cAdd ~(cMul <1> ~<3>) ~(cMul <2> ~<4>))])

## x^2 + x*y = x*(x+y)
## Disabled. This rule conflicts with (x+y)^2 optimization.
#cAdd (cPow [x 2])  (cMul x <1> ~<2>) : (cMul x (cAdd x  (cMul <1> ~<2>)))
#cAdd (cPow [x 2]) ~(cMul x <1> ~<2>) : (cMul x (cAdd x ~(cMul <1> ~<2>)))

# Note: These rules can be applied recursively, causing
# that such as a*b*d*e*f - c*d*e*f*g is first
# changed   to d*(a*b*e*f - c*e*f*g)
# and then  to d*(f*(a*b*e - c*e*g))
# and then  to d*(f*(e*(a*b - c*g)))
# which yields d*f*e*(a*b - c*g)

#
# How about (a+b)*(c+d)?
# It becomes a*c + b*c + a*d + b*d...
# We would like to do optimizations like that in reverse.
# Using the rules specified above,
# a*c + b*c + a*d + b*d might be
# changed  to a*(c+d) + b*(c+d),
# and then to (a+b)*(c+d).
# This seems nice enough.
# But what about (a+b)*(a+b)? This expands into a^2 + 2*a*b + b^2.
# Or,      about (a-b)*(a-b)? This expands into a^2 - 2*a*b + b^2.
# Or,      about (a+b)*(a-b)? This expands into a^2 - b^2.
# It would be nice if these could also be converted back.
# At least we can handle this a^2 - b^2 special case:
#cAdd (cPow[a 2]) ~(cPow[b 2]) : (cMul [(cAdd[a b]) (cAdd[a ~b])])
# ^With this rule,   eval=0.241051 us, optimized = 0.065257 us
# ^Without the rule, eval=0.227828 us, optimized = 0.060658  us
# Tested expression was "pow(x,14)+pow(y,8)+x*x-y*y"
# Oh well. The benchmark results are too varying.
# It does generate some additional opcodes, but it gets one multiplication less.
# Since the difference is not very noticeable, don't use the rule.

# a^2 + a*b*X/Z + b^2 = (a+b)^2 + (X/Z-2)*(a*b)
cAdd (cPow[a 2]) (cPow[b 2]) (cMul a b <1> ~<2>) : (cPow [(cAdd [a b]) 2]) (cMul [a b (cAdd [(cMul <1> ~<2>) -2])])
# For optimizing x^2+2*x*y+y^2:
#  With this rule,    eval=0.287154 us, optimized = 0.0758879 us
#  Without this rule, eval=0.314538 us, optimized = 0.0831386 us
# For optimizing x^2+3*x*y+y^2:
#  With this rule,    eval=0.295956 us, optimized = 0.0781288 us
#  Without this rule, eval=0.300723 us, optimized = 0.075689 us
# The benchmark results seem too varying, so it is hard to tell
# whether this rule had some advantage. It _looks_ like it did
# though, so better keep it, I suppose. -Bisqwit
#
# How about this?
# (a+b+c)^2 = c^2 + 2*b*c + 2*a*c + b^2 + 2*a*b + a^2
# Seems that it becomes:
# a^2 + b^2 + c^2 + 2*((a+b)*c + a*b)
# Is it worth adding rule for making that into (a+b+c)^2?
# Too specific, I suppose.



cAdd (cMul <1> ~<2> <3> ~<4>)  (cMul <1> ~<2> <5> ~<6>) : (cMul <1> ~<2> (cAdd (cMul <3> ~<4>)  (cMul <5> ~<6>)))
cAdd (cMul <1> ~<2> <3> ~<4>) ~(cMul <1> ~<2> <5> ~<6>) : (cMul <1> ~<2> (cAdd (cMul <3> ~<4>) ~(cMul <5> ~<6>)))
# Note: The above two lines can require extremely time-consuming
#       searching.

# These are the same as above, but work also if pow() is expanded
# Note: It would work even with y and z instead of % and &, but we
# limit into numeric literals for simplicity.
cAdd (cMul (cPow[x %]) <3> ~<4>)  (cMul (cPow[x &]) <5> ~<6>) : (cMul (cPow[x MIN(% &)]) (cAdd (cMul <3> ~<4> (cPow[x (cAdd % ~MIN(% &))]))  (cMul <5> ~<6> (cPow[x (cAdd & ~MIN(% &))]))))
cAdd (cMul (cPow[x %]) <3> ~<4>)  (cMul x           <5> ~<6>) : (cMul (cPow[x MIN(% 1)]) (cAdd (cMul <3> ~<4> (cPow[x (cAdd % ~MIN(% 1))]))  (cMul <5> ~<6> (cPow[x (cAdd 1 ~MIN(% 1))]))))
cAdd (cMul (cPow[x %]) <3> ~<4>) ~(cMul (cPow[x &]) <5> ~<6>) : (cMul (cPow[x MIN(% &)]) (cAdd (cMul <3> ~<4> (cPow[x (cAdd % ~MIN(% &))])) ~(cMul <5> ~<6> (cPow[x (cAdd & ~MIN(% &))]))))
cAdd (cMul (cPow[x %]) <3> ~<4>) ~(cMul x           <5> ~<6>) : (cMul (cPow[x MIN(% 1)]) (cAdd (cMul <3> ~<4> (cPow[x (cAdd % ~MIN(% 1))])) ~(cMul <5> ~<6> (cPow[x (cAdd 1 ~MIN(% 1))]))))
cAdd (cMul x           <3> ~<4>) ~(cMul (cPow[x &]) <5> ~<6>) : (cMul (cPow[x MIN(1 &)]) (cAdd (cMul <3> ~<4> (cPow[x (cAdd 1 ~MIN(1 &))])) ~(cMul <5> ~<6> (cPow[x (cAdd & ~MIN(1 &))]))))
# x^7 + x^4*y -> x^4*(x^(7-4) + x^(4-4)*y)
# x^4 + x^7*y -> x^4*(x^(4-4) + x^(7-4)*y)
# x^4 + x^5*y -> x^4*(1 + x*y) BETTER THAN
# x^4 + x^5*y -> x^5*(x^-1 + y)
# Generalized as:
# x^A + x^B*y -> x^MIN(A,B) * (x^(A-MIN(A,B)) + x^(B-MIN(A,B))*y)

#cAdd (cPow[x %]) (cMul (cPow[x +(% -1)]) <1> ~<2>) : (cMul (cPow[x MIN(% &)]) (cAdd (cPow[x (cAdd % ~MIN(% &))]) (cMul (cPow[x (cAdd & ~MIN(% &))]) <1> ~<2>)))

# 2*-x = x*-2
cMul (cAdd [~x])       : -1 x

#    (5.1*x +      4.1*y      + z+w)*2
# -> (5.1*2*x + 2*(4.1*y      + z+w))
# -> (5.1*2*x +   (4.1*2*y + 2*(z+w)))
cMul (cAdd (cMul % <1> ~<2>) <3> ~<4>) &  :  (cAdd (cMul *(% &) <1> ~<2>) (cMul & (cAdd <3> ~<4>)))

#    (2+x+y)*4 = 2*4 + 4*(x+y)
#cMul (cAdd % <1> ~<2>) &  :  (cAdd *(% &) (cMul & (cAdd <1> ~<2>)))
#
# ^ Good idea, but conflicts with cAdd x* (cMul x <1> ~<2>)
#   When given 2*x+2
#     You get 2*(1+x)
#     And     2+ 2*x
#     Alternatingly.
#     To fix, should only be done when % != 1.
#     Unfortunately there's no syntax for that kind of constraints...
#

#### Constant folding is now performed exclusively by ConstantFolding()

#### Logarithm optimizations
# log(x^y) = y*log(x)
cLog [(cPow [p y])] -> cMul [y (cLog[p])]

# log(x^e) = e * log(abs(x))   (e is an even integer)
cLog [(cPow [x e])] -> cMul [e (cLog [(cAbs [x])])]

# CONSTANT_E^log(x) = x
#cPow [CONSTANT_E (cLog[x])]   -> x

# Generalized as:  y^log(x) = x^log(y)
cPow [% (cLog[x])] : x LOG(%)

# Because log(exp(6)*x) = log(x)+6, we can also do this:
#                  y^(log(x)+z)
#                = y^(log(x*exp(z)))
#                = (x*exp(z))^log(y)
#cPow [y (cAdd {(cLog[x]) %})] : (cMul x EXP(%)) (cLog y)
# Probably beneficial to do it only when y is const,
# though. Otherwise we only trade + for *, which is bad.
cPow [& (cAdd {(cLog[x]) %})] : (cMul x EXP(%)) LOG(&)

# CONSTANT_E^(log(x)*y) = x^y
cPow [CONSTANT_E (cMul (cLog[x]) <1> ~<2>)]   :     x  (cMul <1> ~<2>)

# Generalization of the above.
#  Note: if you have exp(log(x)*5), you may get two results (ambiguous rules):
#                   a: x^5            -- the rule above,
#                   b: exp(5)^log(x)  -- the rule below.
#  Naturally, case "a" is more desirable,
#  but if you get "b", the y^log(x) = x^log(y) rule will fix it so it becomes x^5.
cPow [%          (cMul  &        <1> ~<2>)]   : POW(% &) (cMul <1> ~<2>)

# z^(log(x)/log(z)*y) = x^y
cPow [z (cMul ~(cLog[z]) (cLog[x]) <1> ~<2>)] : x (cMul <1> ~<2>)
cPow [% (cMul ~LOG(%)    (cLog[x]) <1> ~<2>)] : x (cMul <1> ~<2>)
cPow [% (cMul /LOG(%)    (cLog[x]) <1> ~<2>)] : x (cMul <1> ~<2>)

# log(x) + log(y) = log(x*y)
cAdd (cLog[x]) (cLog[y]) : (cLog (cMul [x y]))
# When x is const, the reverse is more beneficial
#  i.e.  log(2*x) = log(x) + log(2)
cLog [(cMul % <1> ~<2>)] -> cAdd (cLog [(cMul <1> ~<2>)]) LOG(%)

# log(x * z^y) = (log(x) / log(z) + y) * log(z)
# Only worthwhile when z is an immed
# Note that when z = CONSTANT_E, this reduces rather nicely into log(x) + y
cLog [(cMul (cPow [% y]) <1> ~<2>)] -> cMul [LOG(%) (cAdd [y (cMul (cLog [(cMul <1> ~<2>)]) /LOG(%))])]
# When y=1, the reverse is more useful:
cMul {% (cAdd {1 (cMul {(cLog [x]) /%})})} -> cAdd (cLog [x]) %
#cMul {% (cAdd {1 (cMul {(cLog [x]) /%})})} -> cLog [(cMul LOG(%) x)]


#### Trigonometric:
# sin(-x) = -sin(x)
cSin [(cAdd [~x])] -> cAdd ~(cSin [x])
# cos(-x) = cos(x)
cCos [(cAdd [~x])] : x



# cos(pi/2 - x) = sin(x)
cCos [(cAdd {CONSTANT_PIHALF ~x})] -> cSin[x]
# sin(pi/2 - x) = cos(x)
cSin [(cAdd {CONSTANT_PIHALF ~x})] -> cCos[x]
# cos(x - pi/2) = cos(pi/2 - x) = sin(x)
cCos [(cAdd {~CONSTANT_PIHALF x})] -> cSin[x]
# sin(x - pi/2) = -sin(pi/2 - x) = -cos(x)
cSin [(cAdd {~CONSTANT_PIHALF x})] -> cAdd ~(cCos[x])

# sin(x)^2 + cos(x)^2 = 1
cAdd  (cPow[ (cSin[x]) 2]) (cPow [(cCos[x]) 2]) : 1
# y-sin(x)^2 = cos(x)^2+(y-1)
# y-cos(x)^2 = sin(x)^2+(y-1)
cAdd 1 ~(cPow[ (cSin[x]) 2]) : (cPow [(cCos[x]) 2])
cAdd 1 ~(cPow[ (cCos[x]) 2]) : (cPow [(cSin[x]) 2])

# sin(x)*cos(y) + cos(x)*sin(y) = sin(x+y)
# sin(x)*cos(y) - cos(x)*sin(y) = sin(x-y)
# cos(x)*cos(y) + sin(x)*sin(y) = cos(x+y)
# cos(x)*cos(y) - sin(x)*sin(y) = cos(x-y)

cAdd  (cMul {(cSin[x]) (cCos[y])})  (cMul {(cCos[x]) (cSin[y])}) :  (cSin (cAdd[x  y]))
cAdd  (cMul {(cSin[x]) (cCos[y])}) ~(cMul {(cCos[x]) (cSin[y])}) :  (cSin (cAdd[x ~y]))
cAdd  (cMul {(cCos[x]) (cCos[y])})  (cMul {(cSin[x]) (cSin[y])}) :  (cCos (cAdd[x  y]))
cAdd  (cMul {(cCos[x]) (cCos[y])}) ~(cMul {(cSin[x]) (cSin[y])}) :  (cCos (cAdd[x ~y]))

cAdd ~(cMul {(cSin[x]) (cCos[y])}) ~(cMul {(cCos[x]) (cSin[y])}) : ~(cSin (cAdd[x  y]))
cAdd ~(cMul {(cCos[x]) (cCos[y])}) ~(cMul {(cSin[x]) (cSin[y])}) : ~(cCos (cAdd[x  y]))
cAdd ~(cMul {(cCos[x]) (cCos[y])})  (cMul {(cSin[x]) (cSin[y])}) : ~(cCos (cAdd[x ~y]))
# This one is redudant: It just reaffirms that sin(x) = -sin(-x).
#cAdd ~(cMul {(cSin[x]) (cCos[y])})  (cMul {(cCos[x]) (cSin[y])}) : ~(cSin (cAdd[x ~y]))


#### Self-defeating function calls:

# sin(asin(x)) = x
cSin [(cAsin [x])] -> x

# cos(acos(x)) = x
cCos [(cAcos [x])] -> x

# Note: asin(sin(x)) must not be converted, because
# even though asin(sin(1.1)) = 1.1, asin(sin(1500)) != 1500.

cAbs [(cAdd [~x])] : x

# abs(x)^e -> x^e when e=even integer
cPow [(cAbs[x]) e] : x e



[FINAL1]
# These optimizations are done only once, after the intermediate conversions.
# This process generates high-level opcodes that are not
# expected to be found in the intermediate stage.
#
# Do not generate the following opcodes here:
#     cDiv, cRDiv, cInv, cSub, cRSub, cNeg, cNot
#     cSqrt, cRSqrt, cExp
#     cCsc, cSec, cCot
# Do not reduce add/mul/min/max/and/or lists to two-operand topology.
# Those are done in the bytecode generation automatically.
#

cAtan2 [(cMul  x <1> ~<2>) (cMul  x <3> ~<4>)]   : (cMul <1> ~<2>) (cMul <3> ~<4>)
cAtan2 [(cMul  % <1> ~<2>) (cMul  % <3> ~<4>)]   : (cMul <1> ~<2>) (cMul <3> ~<4>)
cAtan2 [(cMul ~x <1> ~<2>) (cMul ~x <3> ~<4>)]   : (cMul <1> ~<2>) (cMul <3> ~<4>)

# sinh(x)/cosh(x) = tanh(x)
cMul  (cSinh[x]) ~(cCosh[x]) :  (cTanh[x])
cMul ~(cSinh[x])  (cCosh[x]) : ~(cTanh[x])
cMul  (cTanh[x])  (cCosh[x]) :  (cSinh[x])
cMul  (cTanh[x]) ~(cSinh[x]) : ~(cCosh[x])
cMul ~(cTanh[x])  (cSinh[x]) :  (cCosh[x])

# sin(x)/cos(x) = tan(x)
cMul  (cSin[x]) ~(cCos[x]) :  (cTan[x])
cMul ~(cSin[x])  (cCos[x]) : ~(cTan[x])
cMul  (cTan[x])  (cCos[x]) :  (cSin[x])
cMul  (cTan[x]) ~(cSin[x]) : ~(cCos[x])
cMul ~(cTan[x])  (cSin[x]) :  (cCos[x])

# sinh(-x) = -sinh(x)
cSinh [(cAdd [~x])] -> cAdd [~(cSinh [x])]

# cosh(-x) = cosh(x)
cCosh [(cAdd [~x])] : x

# tan(-x) = -tan(x)
cTan [(cAdd [~x])] -> cAdd ~(cTan [x])

# tanh(-x) = -tanh(x)
cTanh [(cAdd [~x])] -> cAdd ~(cTanh [x])


# sinh(x)*2 = (exp(x)-   exp(-x))
# sinh(x)*2 = (exp(x)- 1/exp(x))
# cosh(x)*2 = (exp(x)+   exp(-x))
# cosh(x)*2 = (exp(x)+ 1/exp(x))
cAdd (cPow [CONSTANT_E  x]) ~(cMul [~(cPow [CONSTANT_E  x])]) : (cMul (cSinh [x]) 2)
cAdd (cPow [CONSTANT_E  x])  (cMul [~(cPow [CONSTANT_E  x])]) : (cMul (cCosh [x]) 2)

#        tanh(x) = (exp(2*x)-1) / (exp(2*x)+1)
#      1/tanh(x) = (exp(2*x)+1) / (exp(2*x)-1)
#        tanh(-x) = -tanh(x), so
#       -tanh(x) = (exp(-2*x)-1) / (exp(-2*x)+1)
#     1/-tanh(x) = (exp(-2*x)+1) / (exp(-2*x)-1)
cMul (cAdd {(cPow [CONSTANT_E (cMul {-2 x})]) -1}) ~(cAdd {(cPow [CONSTANT_E (cMul {-2 x})])  1}) : (cAdd ~(cTanh [x]))
cMul (cAdd {(cPow [CONSTANT_E (cMul { 2 x})]) -1}) ~(cAdd {(cPow [CONSTANT_E (cMul { 2 x})])  1}) : (cTanh [x])
cMul (cAdd {(cPow [CONSTANT_E (cMul {-2 x})])  1}) ~(cAdd {(cPow [CONSTANT_E (cMul {-2 x})]) -1}) : ~(cAdd ~(cTanh [x]))
cMul (cAdd {(cPow [CONSTANT_E (cMul { 2 x})])  1}) ~(cAdd {(cPow [CONSTANT_E (cMul { 2 x})]) -1}) : ~(cTanh [x])

# Note: I have no idea why (exp(x)-exp(-x)) / (exp(x)+exp(-x))
#                 produces (exp(2*x)-1) / (exp(2*x)+1)
#       It just says so in Wikipedia.
#       Maybe this could be utilized for more generic optimizations?
#
# Maxima gives that exp(x) + n*exp(-x)
#                 = exp(-x) * (exp(2*x) + n)
# but I still have no idea why is that.
#
# In more generic form:
#   exp(d*y) * ((a * exp(b*x - d*y)) + c)   = a*exp(    b*x) + c*exp(d*y)
#   exp( -y) * ((a * exp(b*x +   y)) + c)   = a*exp(    b*x) + c*exp( -y)
#
#   exp(d*x) * ((a * exp((b-d) * x)) + c)   = a*exp(    b*x) + c*exp(d*x)
#   exp( -x) * ((a * exp((b+1) * x)) + c)   = a*exp(    b*x) + c*exp( -x)
#   exp( -x) * ((a * exp(    b * x)) + c)   = a*exp((b-1)*x) + c*exp( -x)
#   exp(d*x) * ((a * exp((1-d) * x)) + c)   = a*exp(      x) + c*exp(d*x)
#
#   exp(d*y) * ((   -exp(b*x - d*y)) + c)   =  -exp(    b*x) + c*exp(d*y)
#   exp( -y) * ((   -exp(b*x +   y)) + c)   =  -exp(    b*x) + c*exp( -y)
#
# This is quite hairy.
#

# Because sinh(-x) = -sinh(x),
# sinh(x)*-2 = (exp(-x)-exp(x))
cAdd ~(cPow [CONSTANT_E  x]) (cMul [~(cPow [CONSTANT_E  x])]) : (cMul (cSinh [x]) -2)

# exp(x)  = cosh(x)+sinh(x)
# exp(-x) = cosh(x)-sinh(x)
cAdd  (cCosh [x])  (cSinh [x]) : (cPow [CONSTANT_E  x])
cAdd  (cCosh [x]) ~(cSinh [x]) : (cMul [~(cPow [CONSTANT_E  x])])
cAdd ~(cCosh [x]) ~(cSinh [x]) : ~(cPow [CONSTANT_E  x])
cAdd ~(cCosh [x])  (cSinh [x]) : ~(cMul [~(cPow [CONSTANT_E  x])])
cAdd  (cCosh [x]) ~(cPow [CONSTANT_E  x]) : (cSinh [x])
cAdd  (cSinh [x]) ~(cPow [CONSTANT_E  x]) : (cCosh [x])
cAdd ~(cCosh [x])  (cPow [CONSTANT_E  x]) : ~(cSinh [x])
cAdd ~(cSinh [x])  (cPow [CONSTANT_E  x]) : ~(cCosh [x])

# sinh(acosh(x)) = sqrt(x^2 - 1)  (not a typo)
# cosh(asinh(x)) = sqrt(x^2 + 1)  (not a typo)
#  Not sure whether these are faster. They are more opcodes, but
#  simpler. The rationale is in allowing for further optimizations.
cSinh [(cAcosh [x])] -> cPow [(cAdd [(cPow [x 2]) -1]) 0.5]
cCosh [(cAsinh [x])] -> cPow [(cAdd [(cPow [x 2])  1]) 0.5]

#        asinh: log(x + sqrt(x*x + 1))
cLog [(cAdd {x (cPow [(cAdd {(cPow [x 2]) 1}) 0.5])})] -> cAsinh [x]

#        acosh: log(x + sqrt(x*x - 1))
cLog [(cAdd {x (cPow [(cAdd {(cPow [x 2]) -1}) 0.5])})] -> cAcosh [x]

#        atanh:   log( (1+x) / (1-x)) / 2
#        2*atanh: log( (1+x) / (1-x))
cLog [(cMul {(cAdd {1 x}) ~(cAdd {1 ~x})})] -> cMul [(cAtanh [x]) 2]


# cot(pi/2 - x) = 1/tan(pi/2 - x) = tan(x)
#                   tan(pi/2 - x) = 1/tan(x)
#                      reverse is probably better
cMul ~(cTan[x]) : (cTan [(cAdd [CONSTANT_PIHALF ~x])])
cMul (cTan [(cAdd {CONSTANT_PIHALF ~x})]) (cTan [x]) : 1


# tan(atan(x)) = x
cTan [(cAtan [x])] -> x

[FINAL2]

# x * CONSTANT_DR = cDeg(x)
# x * ~CONSTANT_RD = cDeg(x)
cMul  CONSTANT_DR <1> ~<2> -> cDeg [(cMul <1> ~<2>)]
# Note: This may produce one-operand cMul lists.
# Those are treated properly in the bytecode generation,
# and do not need to be handled by [INTERMEDIATE].

# x * CONSTANT_RD = cRad(x)
# x * ~CONSTANT_DR = cRad(x)
cMul  CONSTANT_RD <1> ~<2> -> cRad [(cMul <1> ~<2>)]

# log(x) / CONSTANT_L10  = log10(x)
cMul  (cLog [x]) CONSTANT_L10I  :  (cLog10 [x])
cMul ~(cLog [x])   CONSTANT_L10 : ~(cLog10 [x])

# log(x) / CONSTANT_L2 = log2(x)
cMul  (cLog [x]) CONSTANT_L2I  :  (cLog2 [x])
cMul ~(cLog [x])   CONSTANT_L2 : ~(cLog2 [x])

cAtan [(cMul y ~x <1> ~<2>)] -> cAtan2 [(cMul y <1>) (cMul x <2>)]

# inverted pow is better expressed with negated exponent
#  this makes x^-acos(x) , which is turned into 1/x^acos(x)
#  turn back into x^-acos(x)
# FIXME: only if y is not integer constant
#cMul ~(cPow [x y]) : (cPow [x (cAdd [~y])])
